<!doctype html><html dir=ltr lang=zh-cn data-theme class="html theme--light"><head><meta charset=utf-8><title>覃宇
|
LangChain小试
</title><meta name=generator content="Hugo 0.147.0"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=author content="覃宇"><meta name=description content="用 LangChain 做文章总结"><link rel=stylesheet href=/scss/main.min.1cac29897bb941adf4246700acb99deffbfdf35a02ffc4ae81484456ebe430c3.css integrity="sha256-HKwpiXu5Qa30JGcArLmd7/v981oC/8SugUhEVuvkMMM=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/css/markupHighlight.min.73ccfdf28df555e11009c13c20ced067af3cb021504cba43644c705930428b00.css integrity="sha256-c8z98o31VeEQCcE8IM7QZ688sCFQTLpDZExwWTBCiwA=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/fontawesome.min.137b1cf3cea9a8adb7884343a9a5ddddf4280f59153f74dc782fb7f7bf0d0519.css integrity="sha256-E3sc886pqK23iENDqaXd3fQoD1kVP3TceC+3978NBRk=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/solid.min.e65dc5b48fb5f39b142360c57c3a215744c94e56c755c929cc3e88fe12aab4d3.css integrity="sha256-5l3FtI+185sUI2DFfDohV0TJTlbHVckpzD6I/hKqtNM=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/regular.min.6f4f16d58da1c82c0c3a3436e021a3d39b4742f741192c546e73e947eacfd92f.css integrity="sha256-b08W1Y2hyCwMOjQ24CGj05tHQvdBGSxUbnPpR+rP2S8=" crossorigin=anonymous type=text/css><link rel=stylesheet href=/fontawesome/css/brands.min.e10425ad768bc98ff1fb272a0ac8420f9d1ba22f0612c08ff1010c95080ffe7e.css integrity="sha256-4QQlrXaLyY/x+ycqCshCD50boi8GEsCP8QEMlQgP/n4=" crossorigin=anonymous type=text/css><link rel="shortcut icon" href=/favicons/favicon.ico type=image/x-icon><link rel=apple-touch-icon sizes=180x180 href=/favicons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicons/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicons/favicon-16x16.png><link rel=canonical href=https://qinyu.github.io/post/langchain-101/><script type=text/javascript src=/js/anatole-header.min.f9132794301a01ff16550ed66763482bd848f62243d278f5e550229a158bfd32.js integrity="sha256-+RMnlDAaAf8WVQ7WZ2NIK9hI9iJD0nj15VAimhWL/TI=" crossorigin=anonymous></script><script type=text/javascript src=/js/anatole-theme-switcher.min.8724ddf9268dee451060f191961647573c7f592fbccc6d858746236b3f915813.js integrity="sha256-hyTd+SaN7kUQYPGRlhZHVzx/WS+8zG2Fh0Yjaz+RWBM=" crossorigin=anonymous></script><meta name=twitter:card content="summary"><meta name=twitter:title content="LangChain小试"><meta name=twitter:description content="用 LangChain 做文章总结"><meta property="og:url" content="https://qinyu.github.io/post/langchain-101/"><meta property="og:site_name" content="Qin Yu is writing"><meta property="og:title" content="LangChain小试"><meta property="og:description" content="用 LangChain 做文章总结"><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2023-05-17T00:00:00+00:00"><meta property="article:modified_time" content="2023-05-17T00:00:00+00:00"><meta property="article:tag" content="LangChain"><meta property="article:tag" content="AI"><meta property="article:tag" content="效率"><meta property="og:see_also" content="https://qinyu.github.io/post/learn-prompt-from-langchain/"><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","articleSection":"post","name":"LangChain小试","headline":"LangChain小试","alternativeHeadline":"","description":"
      用 LangChain 做文章总结


    ","license":"","inLanguage":"zh-cn","isFamilyFriendly":"true","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/qinyu.github.io\/post\/langchain-101\/"},"author":{"@type":"Person","name":"覃宇"},"creator":{"@type":"Person","name":"覃宇"},"accountablePerson":{"@type":"Person","name":"覃宇"},"copyrightHolder":{"@type":"Person","name":"覃宇"},"dateCreated":"2023-05-17T00:00:00.00Z","datePublished":"2023-05-17T00:00:00.00Z","dateModified":"2023-05-17T00:00:00.00Z","publisher":{"@type":"Organization","name":"覃宇","url":"https://qinyu.github.io/","logo":{"@type":"ImageObject","url":"https:\/\/qinyu.github.io\/favicons\/favicon-32x32.png","width":"32","height":"32"}},"image":[],"url":"https:\/\/qinyu.github.io\/post\/langchain-101\/","wordCount":"421","genre":[],"keywords":["LangChain","AI","效率"]}</script></head><body class=body><div class=wrapper><aside class=wrapper__sidebar><div class="sidebar
animated fadeInDown"><div class=sidebar__content><div class=sidebar__introduction><img class=sidebar__introduction-profileimage src=/images/profile.jpg alt="profile picture"><div class=sidebar__introduction-title><a href=/>覃宇码字的地方</a></div><div class=sidebar__introduction-description><p>Thoughtworker<br>移动应用架构师<br>技术教练<br></p></div></div><ul class=sidebar__list><li class=sidebar__list-item><a href=https://github.com/qinyu/ target=_blank rel="noopener me" aria-label=GitHub title=GitHub><i class="fab fa-github fa-2x" aria-hidden=true></i></a></li><li class=sidebar__list-item><a href=mailto:qinyusuain@gmail.com target=_blank rel="noopener me" aria-label=e-mail title=e-mail><i class="fas fa-envelope fa-2x" aria-hidden=true></i></a></li></ul></div><footer class="footer footer__sidebar"><ul class=footer__list><li class=footer__item>&copy;
覃宇
2025</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script></div></aside><main class=wrapper__main><header class=header><div class="animated fadeInDown"><a role=button class=navbar-burger data-target=navMenu aria-label=menu aria-expanded=false><span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span>
<span aria-hidden=true class=navbar-burger__line></span></a><nav class=nav><ul class=nav__list id=navMenu><li class=nav__list-item><a href=/ title>主页</a></li><li class=nav__list-item><a href=/post/ title>文章</a></li><li class=nav__list-item><div class=optionswitch><input class=optionswitch__picker type=checkbox id=2 hidden>
<label class=optionswitch__label for=2>作品 <i class="fa fa-angle-down" aria-hidden=true></i></label><div class=optionswitch__triangle></div><ul class=optionswitch__list><li class=optionswitch__list-item><a href=/books/ title>翻译写作</a></li><li class=optionswitch__list-item><a href=/courses/ title>线上课程</a></li></ul></div></li><li class=nav__list-item><a href=/about/ title>关于</a></li></ul><ul class="nav__list nav__list--end"><li class=nav__list-item><div class=themeswitch><a title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></li></ul></nav></div></header><div class="post
animated fadeInDown"><div class=post__content><h1>LangChain小试</h1><ul class=post__meta><li class=post__meta-item><em class="fas fa-calendar-day post__meta-icon"></em>
<span class=post__meta-text>Wed, May 17, 2023</span></li><li class=post__meta-item><em class="fas fa-stopwatch post__meta-icon"></em>
<span class=post__meta-text>阅读时间 2 分钟</span></li></ul><p><em>太长不读版总结（by AI）：</em></p><blockquote><p><em>本文介绍了使用 AI 技术，如 ChatGPT、MapReduce 和 LangChain，来快速生成文章总结的方法。LangChain 是一种可以高效集成大语言模型和各种服务，拓展 AI 能力的工具，可以快速封装成 APP 或 API，并且可以私有部署，以保证数据安全。程序员需要理解业务问题，分析问题，拆分工序，才能保住饭碗。</em></p></blockquote><h1 id=引子>引子</h1><p>有朋友发现上一篇 Wardley Maps 译文（<a href=https://qinyu.github.io/post/wardley-maps/ch6/>迈出第一步</a>）缺少了 Notion AI 做的总结。</p><figure class=small><img src=/post/langchain-101/no_notion_ai.jpeg></figure><p>我使用的免费版 Notion 一共提供了20次使用 Notion AI 的机会（实在是不够）。用完之后，我还是觉得 Notion AI 提供的 Summarize 功能离我的期望还有一些差距。Notion AI 总结的文字最后我还是要进行调整。Notion AI 背后使用的是 OpenAI 的生成式 AI，通过提示词交互。提示词写得好不好，对 AI 生成结果的影响非常明显。如果总结功能的提示词能够调整，生成的结果应该更接近我的期望。但 Notion AI 的 Summarize 功能一个黑盒子，我不知道这个功能的提示词，更没有办法去调整了。我想要的是一个可以调整的总结功能，而不是一个黑盒子。</p><blockquote><p>这里先介绍一下我在翻译 Wardley Maps 时使用的 AI <del>工具</del>副驾吧。首先我会用到 Chrome 插件 Immersive Translate 对原文进行整体翻译，通读译文了解整篇文章的大致内容（还是中文看得更快）。在编辑译文时，每一个段落我都先会用 Bob 翻译（主要是懒得查词、打字）。这里我会同时使用 OpenAI 和有道翻译插件，对比两者翻译结果，选择当中更好的作为译文基础。接下来就要自己进行修改了，比如消除翻译腔，把文字表述改得更加口语化。最后才是用 Notion AI 做总结。</p></blockquote><p>既然我想自己调整总结的提示词，那就别用 Notion AI 和其他类似的总结工具了，自己做一个吧（哪个程序员不喜欢造轮子呢）。</p><h1 id=如何用-ai-总结一篇长文>如何用 AI 总结一篇长文</h1><p>做内容总结使用 ChatGPT 最直截了当。只要用一段类似下面这样的<strong>提示词</strong>向 ChatGPT <strong>提问</strong>，过一会儿 AI 就会<strong>回答</strong>。</p><pre tabindex=0><code>请把下面这段内容用120字简短总结一下：

***
我经常讲到在巴塞罗那艺术酒店碰到的那位聪明的高管。提前透露一个小秘密：我不是唯一假装自己能做高管的人，他也一无所知。但是，这一点是我画了六年地图之后才有人告诉我。我觉得一定有秘诀，而绘制地图不过是效仿别人的笨办法。但事实上大多数行业的做法都是在没有理解形势的情况下直接下场。这就像将军没有地图就投入战斗一样。把命运交给运气和个人英雄主义吧。

...(__这里省去了一万字__)我们将再次展开战略周期循环，看看地图是如何逐步形式化起来的。
***
</code></pre><p>但是 ChatGPT 一次<strong>问答</strong>中能够包含的文字数量有限（准确的说法是 Token 数量有限）。大段的文字会让 ChatGPT 直接罢工。Wardley Maps 每一章动辄上万字的篇幅肯定超过了问答的 Token 数量上限（谢谢作者的<del>碎碎念</del>详细阐述）。如果不能把内容完整地告知 ChatGPT，生成的总结一定会有遗漏，怎么办呢？</p><p>这个问题对程序员来说并不难，分而治之呗。既然一次问答的 Token 数量有限，我就把 Wardley Maps 的每一章<strong>分</strong>成几个小段，分别用 ChatGPT 生成总结。最后再把这些小段的总结<strong>合</strong>起来（或者再次进行总结）就可以得到整篇文章的总结了。你瞧，我们完成了一次经典的 <strong>Map（分）Reduce（合）</strong> 算法。</p><blockquote><p>MapReduce是一种让计算机协同处理大型任务的编程方式。这就像是有一个团队的员工，每个人都负责完成一小部分工作，最终将工作集合起来以更快完成任务。这种方法通常用于分析大量数据或创建复杂的计算机程序。MapReduce通过将这些任务分解为较小的部分，让不同的计算机协同处理，从而使这些任务更快捷、更高效。&ndash;来自AI对维基百科的总结。</p></blockquote><p>一个懒惰的程序员一定不会<strong>一次次</strong>地把小段的文字粘贴到 ChatGPT 里再把答案复制出来。这是典型的重复劳动，应该用程序/工具/代码来解决，比如 LangChain。</p><h1 id=langchain-登场>LangChain 登场</h1><p>LangChain 是啥？先让 AI 来回答一下。</p><blockquote><p>LangChain 是一个软件开发框架，旨在简化使用大型语言模型（LLM）创建应用程序的过程。作为一种语言模型集成框架，LangChain 的用例类似于语言模型，包括<strong>文档分析和摘要</strong>、聊天机器人和代码分析。由 Harrison Chase 开发，LangChain 预计将于 2022 年 10 月发布，使用 Python 和 JavaScript 编写，采用 MIT 许可证。&ndash;来自AI对维基百科的总结。</p></blockquote><p>我用程序员更习惯的语言来解释一下LangChain能干什么：</p><ol><li>LangChain 是一个集成大语言模型（名字中的 Lang）以及其它服务的框架。比如读取各种离线和在线的内容，包括文本、视频等等，这些内容可以变成和 AI 交互的语料。</li><li>LangChain可以调用各种 AI 大语言模型的 API（包括 OpenAI 在内），通过代码访问 AI 的能力而不是和 ChatGPT 在浏览器里进行文本交互。</li><li>Python 和 JavaScript 编写的程序都可以使用 LangChain 的能力（目前 Python 的生态和功能更加丰富一些，推荐使用 Python）。</li><li>LangChain 封装了不少和 AI 交互的模式，例如管理提示词的 PromptTemplate，又比如和语言模型进行多轮交互的 Chain（名字的另一半）。我们前面 MapReduce 的例子即可以看做是一组 Chain。MapReduce 这种算法 LangChain 都帮我们做好了。</li><li>&mldr;</li></ol><p>以上这些能力足够我们实现文章总结功能了。当然 LangChain 还有其他更复杂更高阶的功能，比如管理多次交互的上下文，将信息内容变成向量存储方便语义化搜索等等。有兴趣的读者可以查看<a href=https://langchain.readthedocs.io/en/latest/>LangChain 的文档</a>。</p><h1 id=show-me-the-code>Show me the Code</h1><blockquote><p>想要自己动手的读者请先参考 LangChain Python 的 <a href=https://python.langchain.com/en/latest/getting_started/getting_started.html>Quickstart Guide</a>准备环境（下面代码示例使用的是 python）。
另外还需要准备好 OpenAI 的 API Key（可以在<a href=https://platform.openai.com/>这里</a>申请），并设置为环境变量（参考上面 Quickstart Guide）。</p></blockquote><p>我们的算法前面已经讲了，如果要用 LangChain 实现，需要：</p><ol><li>加载文章内容（这里我们直接使用<code>WebBaseLoader</code>加载博客网页内容）。</li><li>把文章内容分成小段（这里我们使用<code>RecursiveCharacterTextSplitter</code>）。</li><li>初始化的提示词（每一小段的文字内容是不一样的，这里我们用<code>PromptTemplate</code>处理变化的内容）</li><li>初始化大语言模型（这里我们使用<code>OpenAI</code>）</li><li>用 Chain 实现 MapReduce 算法：先总结每一小段，再合并总结（这里我们使用现成的<code>load_summarize_chain</code>）</li></ol><p>上代码吧。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> typing <span style=color:#f92672>import</span> List, Any
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.docstore.document <span style=color:#f92672>import</span> Document
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.document_loaders <span style=color:#f92672>import</span> WebBaseLoader
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.text_splitter <span style=color:#f92672>import</span> RecursiveCharacterTextSplitter
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.chains.summarize <span style=color:#f92672>import</span> load_summarize_chain
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain <span style=color:#f92672>import</span> OpenAI
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain.prompts <span style=color:#f92672>import</span> PromptTemplate
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>HugoPostLoader</span>(WebBaseLoader):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;针对 Hugo 博客的文章加载器（非常简单的爬虫技巧，和AI关系不大）&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>pass</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>prompt_template <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>Write a summary of the following:
</span></span></span><span style=display:flex><span><span style=color:#e6db74></span><span style=color:#e6db74>{text}</span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span><span style=color:#e6db74>SUMMARY IN&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_get_blog_documents</span>(blog_url):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;加载博客文章并拆分成多段&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># RecursiveCharacterTextSplitter默认按照行、空白字符递归拆分</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># 拆分成的每一段的长度不超过1500个字符（不会超过 OpenAI 的 token limit）</span>
</span></span><span style=display:flex><span>    text_splitter <span style=color:#f92672>=</span> RecursiveCharacterTextSplitter(chunk_size<span style=color:#f92672>=</span><span style=color:#ae81ff>1500</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> HugoPostLoader(blog_url)<span style=color:#f92672>.</span>load_and_split(text_splitter)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_get_map_prompt</span>(prompt_template, lang<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Chinese&#34;</span>):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;初始化提示词，text会被换成每一小段的文字内容&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> PromptTemplate(template<span style=color:#f92672>=</span>prompt_template<span style=color:#f92672>+</span><span style=color:#e6db74>f</span><span style=color:#e6db74>&#34; </span><span style=color:#e6db74>{</span>lang<span style=color:#e6db74>}</span><span style=color:#e6db74>:&#34;</span>,
</span></span><span style=display:flex><span>                          input_variables<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;text&#34;</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>summarize_blog</span>(url, lang):
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;总结博客文章，url是博客的网址，lang是语言&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    map_prompt <span style=color:#f92672>=</span> _get_map_prompt(prompt_template, lang)
</span></span><span style=display:flex><span>    <span style=color:#75715e># OpenAI 的 temperature 参数控制生成的文本的多样性</span>
</span></span><span style=display:flex><span>    llm <span style=color:#f92672>=</span> OpenAI(temperature<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span>    <span style=color:#75715e># load_summarize_chain 会自动初始化 Chain，采用 MapReduce 算法</span>
</span></span><span style=display:flex><span>    chain <span style=color:#f92672>=</span> load_summarize_chain(
</span></span><span style=display:flex><span>        llm, chain_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;map_reduce&#34;</span>, map_prompt<span style=color:#f92672>=</span>map_prompt)
</span></span><span style=display:flex><span>    data <span style=color:#f92672>=</span> _get_blog_documents(url)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> chain<span style=color:#f92672>.</span>run(data)
</span></span></code></pre></div><p>代码不长，很容易理解。来看看效果吧。</p><p>执行：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>url <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;https://www.qinyu.info/post/wardley-maps/ch6/&#34;</span>
</span></span><span style=display:flex><span>lang <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;Chinese&#34;</span>
</span></span><span style=display:flex><span>print(summarize_blog(url, lang))
</span></span></code></pre></div><p>输出：</p><pre tabindex=0><code>本文探讨了在组织内部落地Wardley Map的思路，技巧、术语和符号，以及反模式，以帮助检查组织势态感知能力。作者还推荐了一些书籍，介绍通用的战略概念。本文还提供了一套通用的符号，用于绘制地图，以及防止业务部门破坏流程的反模式组织。
</code></pre><p>这段代码基本完成了我们想要的功能，但还有一些小问题：</p><ol><li>如果拆分的段落语义更好，总结的效果会更好。例如中文的段落拆分可以按照标点符号而不是空白字符拆分。</li><li>最后把所有段落的总结汇集成一个总结的提示词还可以再优化一下，这样生成的总结会更加连贯。</li></ol><p>上面这段代码我还部署到了 Streamlit 上，可以直接在浏览器里使用。没有环境的读者可以直接在[这里](<a href=https://web-summarizer-qy.streamlit.app/>https://web-summarizer-qy.streamlit.app/</a>）尝试效果（如果出错，可能是 OpenAI 的 API 访问次数限制）。</p><blockquote><p>Streamlit 是一个 Python 库，可以让你在几行代码内构建数据应用。所有的应用都是纯 Python，可以在你的浏览器中实时交互。&ndash;来自<a href=https://www.streamlit.io/>Streamlit官网</a>的解释。（来自 Copilot）</p></blockquote><p>所有代码可以在 github 上找到：https://github.com/qinyu/langchain-playground/tree/main/blog-summarize。</p><h1 id=被-copilot-惊艳xia到了>被 Copilot 惊艳（xia）到了</h1><blockquote><p>Copilot 是一个基于 OpenAI Codex 的 VS Code 插件，可以帮助你写代码。&ndash;来自<a href=https://copilot.github.com/>官网</a>的解释。（来自 Copilot）</p></blockquote><p>完成上述所有 python 代码的过程中，Copilot 随时都在旁边默默地观察。Copilot 会给出一些代码建议，有时候还会给出完整的代码（见下图，只有蓝框中的代码是我敲的或是用 VS Code 重构的）。就连参数值居然都是我期望的逻辑，例如页面的 title 和 icon。如果我在 markdown 的文字内容里写了中文，接下来表单的元素的文字就是中文&mldr;。Copilot 帮我完成了 70%的代码！</p><figure class=medium><img src=/post/langchain-101/copilot-generated-code.jpeg></figure><p>作为一个两年多没写过 python、第一次接触 Streamlit 声明式 UI 语法的程序员，完成 Streamlit App 的开发和部署只用了差不多半小时（还包括了 Github 提交代码和 Streamlit 的配置时间）。这个效率真的是惊艳（xia）到了我。</p><p>整个代码编写调试一共花了半天左右的时间​。</p><p>而我在写文章的时候，Copilot 也会跃跃欲试，但效果时好时坏，例如下图这段文字就被放弃了（看来 Copilot 还不太擅长过于开放的上下文）：</p><figure class=medium><img src=/post/langchain-101/copilot-generated-text.jpeg></figure><h1 id=启发>启发</h1><p>关于 LangChain:</p><ol><li>利用 LangChain 可以非常高效地集成大语言模型和各种服务，拓展现有工具的 AI 能力。</li><li>LangChain 可以快速封装成 APP 或者 API（使用 Flask 或者 FastAPI），集成到其它工具中降低使用门槛。</li><li>为了数据安全，LangChain 还需要可以接入私有部署的大语言模型（例如 <a href=https://github.com/imClumsyPanda/langchain-ChatGLM>https://github.com/imClumsyPanda/langchain-ChatGLM</a>）</li><li>为了数据安全，使用 LangChain 包装的 AI 服务可以私有部署，还需要类似 Streamlit 这样可以托管服务的基础设施（类似 Serverless）</li></ol><p>最后&mldr;</p><p>程序员只有能够理解并表述得清楚业务问题、会分析问题、会拆分工序（tasking）的才能保住饭碗。</p><p>拥抱变化吧！</p><p>本文作者为<strong>覃宇</strong>，分享需遵循<a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA 4.0</a>许可。</p><h3>这个系列的帖子</h3><ul><li><a href=/post/learn-prompt-from-langchain/>跟着 LangChain 学 Prompt</a></li><li><a href=/post/langchain-101/>LangChain小试</a></li></ul></div><div class=post__footer><span><a class=tag href=/tags/langchain/>LangChain</a><a class=tag href=/tags/ai/>AI</a><a class=tag href=/tags/%E6%95%88%E7%8E%87/>效率</a></span></div></div></main></div><footer class="footer footer__base"><ul class=footer__list><li class=footer__item>&copy;
覃宇
2025</li></ul></footer><script type=text/javascript src=/js/medium-zoom.min.1248fa75275e5ef0cbef27e8c1e27dc507c445ae3a2c7d2ed0be0809555dac64.js integrity="sha256-Ekj6dSdeXvDL7yfoweJ9xQfERa46LH0u0L4ICVVdrGQ=" crossorigin=anonymous></script></body></html>